<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Tomohiro HAYASE (早瀬 友裕)</title>

  <link rel="stylesheet" href="style.css" type="text/css">
  <link rel="stylesheet" href="top-button.css" type="text/css">

  <!-- Fonts from googleapis.com (usable only online)-->
  <!--sans-serif-->
  <link href='https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300' rel='stylesheet' type='text/css'>

  <link href='https://fonts.googleapis.com/css?family=Open+Sans:300' rel='stylesheet' type='text/css'>
  <!--serif-->
  <link href='https://fonts.googleapis.com/css?family=Libre+Baskerville:400,700' rel='stylesheet' type='text/css'>
  <!--<link href='https://fonts.googleapis.com/css?family=BenchNine:400,300' rel='stylesheet' type='text/css'>-->



  <!--To find scripts, see end of index.html-->
</head>



<body>


<!-- main content-->
<div id="container">

<header id="header">
  <table align="center" border="0" cellpadding="0" cellspacing="0">
  <tbody>
  <tr>
    <td width="80", valign=bottom algin="left">
      <h4>T. HAYASE</h4>
    </td>
    <td valign="bottom"  align="left" >
     <h4><a href="#interests" class="menu">II  INTERESTS</a></h4>
    </td>
    <td width=15>
    <td valign="bottom" align="left" >
      <h4><a href="#papers" class="menu">II  PAPERS</a></h4>
    </td>
    <td width=15>
    <td valign="bottom"  align="left">
      <h4><a href="#talks" class="menu">II  TALKS</a></h4>
    </td>
    <td width=15>
    <td valign="bottom"  align="left">
      <h4><a href="#jobs" class="menu">II JOBS</a></h4>
    </td>
    <td width=15>
    <td valign="bottom"  align="left">
      <h4><a href="#profile" class="menu">II PROFILE</a></h4>
    </td>


    <td width=160>

    <td valign=bottom algin="right">
      <h4>
      <script type="text/javascript">
      document.write("Last update: " + document.lastModified);
      </script>
      </h4>
    </td>
  </tr>
  </tbody>
  </table>

  <table valign="TOP" align="center" border="0" cellpadding="0" cellspacing="0">
  <tbody>
  <tr>

  </tr>
  </tbody>
  </table>

<hr class="header">
</header>
<!--Top table-->
<div id="top">
<div align="center", style="margin-top:20px">
    <iframe allowtransparence="true" width="360", height="360",frameborder="10" ,
        src="https://www.shadertoy.com/embed/wt3BRX?gui=false&t=10&paused=false&muted=false" 
        style="overflow:hidden;">
      </iframe>
</div>      
<div>
  <table valign="TOP" align="center" border="0" cellpadding="0" cellspacing="0">
  <tbody>
    <tr>

      <!-- 
      <td width="900" valign=bottom>
        <img src="yokohama.jpg" width="100%" border="0">
      </td>
    --> 
    </tr>
    <tr valign="center" width="750" >
     <h1>Tomohiro HAYASE, Ph.D. (Math.Sci.)<br>  
     早瀬 友裕, 博士(数理科学) </h1>
    </tr>
</tbody>
</table>




</div><!--End of Top menu-->

<div id="sections">
<section>
  <h2 id="interests">Interests</h2><hr class="title">
  My research interests include not only  Free Probability Theory itself, but also its applications.
  Random Matrix Theory, Statistical Learning Theory, Operator Algebras, Functional analysis, Quantum Information Theory are also in my interests.
  Currently I am working on the analysis of deep networks with random weight via free probability theory. 

  <Object type="text/html" data="research_interest_diagram.html" height="600" width="800"></Object>
</section>

<section>
  <h2 id="new">New</a></h2><hr class="title">
    <ol>
	<li>Benoit Collins, Tomohiro Hayase, <br>
	"Asymptotic Freeness of Layerwise Jacobians Caused by Invariance of Multilayer Perceptron : The Haar Orthogonal Case" <br>
	arXiv preprint, <a href="https://arxiv.org/abs/2103.13466">arXiv:2103.13466</a>	</li>
	    
	    
	    <li> Kubota Shohei, Hideaki Hayashi, Tomohiro Hayase, Seiichi Uchida, <br>
	"Layer-wise Interpretation of deep neural networks usng identity initialization" <br>
	    accepted into ICASSP 2021, <a href="https://arxiv.org/abs/2102.13333">arXiv:2102.13333</a>
    </li>	      
    <li>Takefumi Hiraki, Tomohiro Hayase,  Yuichi Ike, Takashi Tsuboi, Michio Yoshiwaki, <br>
	"Viewpoint Planning of Projector Placement for Spatial Augmented Reality using Star-Kernel Decomposition",<br>
  IEEE VR 2021, <a href="https://conferences.computer.org/vrpub/pdfs/VRW2021-2ANNoldm4A10Ml9f63uYC9/136700a583/136700a583.pdf">Link to Paper</a>
    </li>	      
    <li>T. Hayase, Ryo Karakida, "The Spectrum of Fisher Information of Deep Networks Achieving Dynamical Isometry",<br>
       accepted into AISTATS2021, <a href="https://arxiv.org/abs/2006.07814">arXiv:2006.07814</a>.
     </li>
    <li>T.Hayase, Suguru Yasutomi, Takashi Kato, "Selective Forgetting of Deep Networks at a Finer Level than Samples", <br>
       accepted into AAAI RSEML2021,  <a href="https://arxiv.org/abs/2012.11849">arXiv:2012.11849</a>
    </li>	      
	</ol>
</section>	


<section>
  <h2 id="profile">Profile</h2><hr class="title">

  <div id="parent">
    <div id="child1">
<a class="twitter-timeline"  
data-hight="200" width="30%"
data-chrome="nofooter noheader"
data-tweet-limit="2"
href="https://twitter.com/ThayaFluss?ref_src=twsrc%5Etfw">Tweets by ThayaFluss</a> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>

  <div id="child2">
	  <ul>
      <li>
        <a href="https://github.com/ThayaFluss" >Github</a>
      </li>

      <li>
        <a href="https://twitter.com/ThayaFluss">Twitter</a>

       </li>
       <li>
        <a href="https://notion-blog-jr3qhisnq-thayafluss.vercel.app/">Notion-Blog</a>
       </li>
       <li>
        e-mail: hayafluss[at]gmail.com
      </li>
      <li>
        Current Affiliation: Fujitsu Labolatories LTD.
       </li>
      <li>
        <a href="cv.html">CV</a>
      </li>
	</ul>
    </div>

</div>

</section>

		  
<section>
  <h2 id="schedule">Talk Schedule</a></h2><hr class="title">	
	The symbol * indicates an invited talk 
  <ol>
	<li> 2021/Feb./8 (16:00 - 21:00 PST), <br>
             "Selective Forgetting of Deep Networks at a Finer Level than Samples", AAAI21 W25: Toward Robust, Secure and Efficient Machine Learning
	</li>	
	<li> 2021/Feb./3, (11:15--12:15 JST), <br>
             * ”深層神経回路の数理：無限次元近似, ランダム行列, 及び自由確率論”　RIMS共同研究「作用素環と量子力学系」<br>
	(Abstract)深層神経回路(DNN)は階層構造を持つ統計モデルです. 2017年以降, DNNの理論の重要な部分にランダム行列と自由確率論が現れたその経緯を紹介します. 
基本的な理論設定では, DNNとして実ベクトル入力に（パラメトリックな）線形変換と要素毎の非線形変換を繰り返す関数を考え,　DNNのパラメータは確率的勾配降下法で最適化されます. 
(i)まず, 層数の増加に伴う勾配の発散・消失はDNNにおける重要な問題でした.  
Pennigntonらは初期状態のDNNを考え,　層の幅（次元）が十分大きいと仮定することで,  勾配発散・消失問題をランダム行列の積のスペクトル解析に帰着しました. 
その結果, 彼らは層が深くともDNNを素早く最適化する初期化設定を導きました. 
(ii)次に, 様々な研究(Jacot+)によって, 「十分幅の大きいDNNの最適化ダイナミクスはNeural Tangent Kernel (NTK)による線形発展で近似される」という仮説が検証されています. 
このNTKは初期状態における勾配の共分散行列であり, ランダム行列理論が解析に欠かせません.  
追記すると, NTKの仮説からおよそ「パラメータを無限次元まで拡張すれば, DNNの最適化は線形回帰に帰着される」ということが従います. 
この発表では , 以上二つのテーマについて関数解析・作用素環領域向けに紹介します. （DNNの知識不要です.）
	</li>	
   </ol>
</section>	

<section>
	<h2 id="preprints">Preprints</a></h2><hr class="title">
	<ol reversed>
		<li>Benoit Collins, Tomohiro Hayase, <br>
	"Asymptotic Freeness of Layerwise Jacobians Caused by Invariance of Multilayer Perceptron : The Haar Orthogonal Case" <br>
	arXiv preprint, <a href="https://arxiv.org/abs/2103.13466">arXiv:2103.13466</a>	</li>

    <li><del>T. Hayase"Almost surely asymptotic freeness for Jacobian spectrum of deep networks",<br>
       arXiv preprint, <a href="https://arxiv.org/abs/1908.03901">arXiv:1908.03901 [math.PR]</a>.<del>
     </li>
</ol>
</section>
	
	
	
<section>
  <h2 id="papers">Full Papers</a></h2><hr class="title">

  <ol reversed>
    <li>T. Hayase, "Identifiability of parametric random matrix models",<br>
        Infinite Dimensional Analysis, Quantum Probability and Related Topics Vol. 22, No. 03, 1950018 (2019). <br>
       (<a href="https://arxiv.org/abs/1812.10678">arXiv:1812.10678 [math.PR]</a>)
     </li>	  
    <li>T. Hayase, "Cauchy noise loss for stochastic optimization of random matrix models via free deterministic equivalents",<br>
        Journal of Mathematical Analysis and Applications Vol. 483, Issue 2, 123597 (2020). <br>
       (<a href="https://arxiv.org/abs/1804.03154">arXiv:1804.03154 [stat.ML]</a>).
     </li>
    <li>T. Hayase, "Free deterministic equivalent Z-scores of compound Wishart models: A goodness of fit test of 2DARMA models",<br>
  RMTA, No.08, Issue No. 02. (2019). <br>
       ( <a href="https://arxiv.org/abs/1710.09497">arXiv:1710:09497 [math.ST]</a> ) 
     </li>
    <li>T. Hayase, "De Finetti theorem for a Boolean anaolgue of easy quantum groups",<br>
       <i>J. Math. Sci.</i>, vol. 24, no. 03, pp. 355~398, 2017    ( <a href="http://arxiv.org/abs/1507.05563">arXiv:1507.05563 [math.OA]</a>).
     </li>
  </ol>
</section>

	
	
<section>
  <h2 id="conference">International conference and workshop</a></h2><hr class="title">
  <ol reversed>
    <li>T.Hayase, S.Yasutomi, Takashi Kato, "Selective Forgetting of Deep Networks at a Finer Level than Samples", <br>
	    accepted into RESEML2021, <a href="https://arxiv.org/abs/2012.11849">arXiv:2012.11849</a>.
    </li>	    	  
    <li>T. Hayase, "The Spectrum of Fisher Information of Deep Networks Achieving Dynamical Isometry",<br>
            accepted into AISTATS2021, <a href="https://arxiv.org/abs/2006.07814">arXiv:2006.07814</a>.
     </li>
    <li>Takefumi Hiraki, Tomohiro Hayase,  Yuichi Ike, Takashi Tsuboi, Michio Yoshiwaki, <br>
	"Viewpoint Planning of Projector Placement for Spatial Augmented Reality using Star-Kernel Decomposition"  <br>
	    accepted into IEEE VR 2021 Poster Track. 
    </li>	       
    <li> Kubota Shoheim Hideaki Hayashi, Tomohiro Hayase, Seiichi Uchida, <br>
	"Layer-wise Interpretation of deep neural networks usng identity initialization" <br>
	    accepted into ICASSP 2021.
    </li>	      	
   </ol>
</section>


<section>
  <h2 id="workshops"> Organized Workshops </a></h2><hr class="title">
  <ol reversed> 
    <li> <a href="https://thayafluss.github.io/free_meetup/">Workshop on free probability, mean field, and neural networks </a>	    
    </li>
    <li> <a href="https://thayafluss.github.io/rfm/">Random Matrices, Free Probability, and Machine Learning</a>	    
    </li>
</ol>
</section>


<section>
  <h2 id="talks">Talks</h2><hr class="title">
    <h3 id="conferences">Conferences</h3>

    The symbol * indicates an invited talk 

  <ol reversed>
    <li>* 自由確率論による深層神経回路網の解析, 情報系 WINTER FESTA Episode 5, Dec., 2019
    </li>

    <li> (Poster) Asymptotic Freeness in Jacobian of Deep Neural Networks, ACML, Nagoya, Nov., 2019
    </li>

    <li> (Poster) Asymptotic Freeness in Jacobian of Deep Neural Networks, Deep Learning and Physics 2019, Yukawa Institute for theoretical physics, Kyoto Univ, Nov., 2019
    </li>

    <li> 
    (<a href="posters/poster_meiji.pdf">Poster</a>) Spectral Parameter Estimation of Random Matrix Models (Cauchy雑音損失による次元復元),<br>
	    異分野異業種交流会, Meiji University, (Japan), Nov., 2018  
    </li>	  
	  
    <li>
    (<a href="posters/poster_ibis.pdf">Poster</a>) Spectral Parameter Estimation of Random Matrix Models,<br>
	IBISML (情報論的学習理論), Sapporo (Japan), Nov., 2018
    </li>

      <li>
     *Parameter Estimation of Random Matrix Models via Free Probability Theory,<br>
      Recent Development of Operator Algebras, Sep., 2018.
    </li>
	  
    <li>
    (<a href="posters/cnl_poster.pdf">Poster</a>) Cauchy noise loss for stochastic optimization of random matrix models via free deterministic equivalents, Random matrices and their applications, Kyoto University (Japan), May, 2018
    </li>

      <li>
      Cauchy noise loss: A machine learning approach to random matrices and free probability, Noncommutative probability theory and its applications, <a href="http://www.ocha.ac.jp/">Ochanomizu University</a> (Japan), Dec., 2017
    </li>

    <li>
      *De Finetti theorems for a Boolean analogue of easy quantum groups<br>
      Free Probability and the Large N Limit, V, <a href="https://math.berkeley.edu/">UC Berkeley</a> (USA), Mar., 2016
    </li>


    <li>
      Free product of von Neumann algebras<br>
    Workshop of Free monotone transport, Tiba (Japan), Mar., 2016. 
    </li>

    <li>
        Cumulants in noncommutative probability<br>
        The 50-th Functional Analysis Workshop, Karuizawa (Japan), Sep., 2015.
    </li>

    <li>
     A symmetry in free probability: Quantum de Finetti theorem<br>
          The 49-th Functional Analysis Workshop, Gifu (Japan), Aug., 2014.
       </li>
   </ol>



  <h3 id="seminars">Seminars</h3>
  <ol reversed>

    <li>
     自由確率論による深層神経回路網の解析, 東工大, 6/28, 2019
    </li>

	 <li> 
  Workshop on Free Probability Theory, Mean Field Theory, and Neural Networks, 2/25 東京大学 柏キャンパス <a href="https://thayafluss.github.io/free_meetup">(program)</a>
   </li>
	  
	  	  
      <li>
	Strong Tools in Free Probability Theory,<br>
	Operator Algebras Seminar, The University of Tokyo (Japan), Oct., 2018.
    </li>

	  
    <li>
      On Cauchy noise loss in a stochastic parameter optimization of random matrices,<br>
      Operator Algebras Seminar, The University of Tokyo (Japan), Feb., 2018.
    </li>


    <li>
      An inverse problem in random matrix theory and free probability theory,<br>
      Functional analysis seminar,
      <a href="https://www.uni-saarland.de/en/info/university.html">Saarland university</a> (Germany),   Nov., 2017
    </li>

    <li>
      An inverse problem in random matrices and free probability, <br>
      research seminar, <a href="http://www.ihp.fr/en">Institute Henri Pincare, UPMC</a> (France), Nov., 2017
    </li>
    <li>
      Bayesian statistics and random matrices, <br>
      Functional analysis seminar, <a href="http://www.math.sci.hokudai.ac.jp/en/"> Department of Mathematics, Hokkaido University</a> (Japan), Aug., 2017
    </li>


    <li>
      Fluctuation of random matrices and genus expansion, <br>
      Operator algebras seminar, <a href="http://www.kyoto-u.ac.jp/ja"> Kyoto University</a> (Japan), July, 2017
    </li>


    <li>Compression of convolutional layers by variational Bayesian matrix factrorization<br> (Japan), Harada lab weakly seminar, <a href= "http://www.i.u-tokyo.ac.jp/">Graduate School of Information Science and Technology, The University of Tokyo</a> (Japan),   June, 2017.  (<a href="slides/compression.pdf">slide</a>)
    </li>
    <li>Genus expansion of random matrices and free deterministic equivalents,<br>
      Free probability seminar, <a href="http://www.ocha.ac.jp/">Ochanomizu University</a> (Japan), May, 2017
    </li>
    <li>
    De Finetti theorems for a Boolean analogue of easy quantum groups,<br>
    Free probability seminar,
        <a href="https://www.uni-saarland.de/en/info/university.html">Saarland university</a> (Germany), Aug., 2015.
    </li>
    <li>
    De Finetti theorems for a Boolean analogue of easy quantum groups<br>
        Operator algebras seminar, The University of Tokyo (Japan), July, 2014.
    </li>

   </ol>

</section>

<section>
  <h2 id="workshops"> Grants </a></h2><hr class="title">
  <ol reversed> 
    <li> JSPS Sakura Program "ランダム行列とランダムテンソルの量子情報と機械学習への応用"
(福田 素久) "Random matrices and tensors for quantum information and machine learning"
(Nechita, Ion),  2020~ 
    </li>
    <li> JST ACT-X 「数理と情報」領域、「自由確率論による深層学習の研究」 2019~ 	    
    </li>
</ol>
</section>

	
	
<section style="margin-bottom:200px;">
  <h2 id="jobs">Jobs</h2><hr class="title">

  <h3 id="reseach-job"> Research Jobs</h3>
    <ol reversed>
      <li>
	  Researcher (Machine Learning and Applied Math)  at Fujitsu Laboratories LTD., May, 2019 ~
      </li>
      <li>
          Internship (Machine Learning / Deep Learning Theory) at Preferred Networks inc., July ~ Sep. , 2018.
      </li>
      <li> Researcher (Free Probablity Thoery) at Institute Henri Poincare (France), Sep. ~ Nov., 2017.
      </li>
      <li>
          Assistant Researcher (Object Detection and Classification) at Morpho inc., 2016 ~ 2017.
      </li>

      </ol>

  <h3 id="teaching"> Teaching Jobs</h3>
    <ol reversed>
      <li>
	  Part-time lecturer, Information Theory, Nov, 2020 ~ May, 2021 @ Ochanomizu University 
      </li>
      <li>
          Teaching assistant, Analisys class III, A semester, 2015 @ The University of Tokyo
      </li>

        <li>
            Teaching assistant, Analisys class III, winter semister, 2014 @ The University of Tokyo
        </li>
      </ol>

	
</section>




</div>


<header id="footer">
<hr class="header">
<table>
<tr>
  <td width=200px align=right valign=top>
  <!--  English / <a href="index_j.html">Japanese</a> -->
	<a href="https://github.com/ThayaFluss/Thayafluss.github.io">source</a>
	</td>

  <td width=600px>
    Tomohiro Hayase (hayafluss [at] gmail.com)<br>
   </td>
</tr>
</table>
</header>


</div><!--End of the main contents-->


<!--Back to Top button -->
<!--
<div id="page-top" class="page-top">
	<p><a id="move-page-top" class="move-page-top"> Top</a></p>
</div>
-->


<!-- Scripts -->
<script type="text/javascript" src="http://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script>
<script src="smooth-scroll.js"></script>
<script src="top-scroll.js"></script>

</body>
</html>
